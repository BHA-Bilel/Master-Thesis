from io import StringIO

import matplotlib
import pickle
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.model_selection import train_test_split
from csv import DictReader, DictWriter
from random import shuffle
import joblib
from sklearn import metrics
from webapp.qasystem.model.preprocess_docs import pre_process
from webapp.qasystem.utils import get_class_dataset, update_cl_report
from os.path import dirname, abspath
import sys

matplotlib.use('Agg')

# generated by code
MODEL_PATH = dirname(abspath(__file__)) + "/models/scikit_class/class.model"
TFIDF_PATH = dirname(abspath(__file__)) + "/models/scikit_class/tfidf"
TOPIC_ID_DF_PATH = dirname(abspath(__file__)) + "/models/scikit_class/topic_id_df"


def create_csv():
    new_csvfile = StringIO()
    columns = ['id', 'document', 'topic']
    writer = DictWriter(new_csvfile, fieldnames=columns)
    writer.writeheader()
    dataset, dataclass_size, topics = get_class_dataset()
    i = 0
    for corp in dataset:
        for data in corp:
            document = pre_process(data.question)
            writer.writerow({'id': data.id, 'document': document, 'topic': topics[i]})
        i += 1
    new_csvfile.seek(0)
    return new_csvfile, dataclass_size


def shuffle_csv(csv):
    reader = DictReader(csv)
    data = []
    for row in reader:
        data.append(row)
    rest = data[1:]
    shuffle(rest)

    new_csvfile = StringIO()
    columns = ['id', 'document', 'topic']
    writer = DictWriter(new_csvfile, fieldnames=columns)
    writer.writeheader()
    for row in rest:
        writer.writerow(row)

    new_csvfile.seek(0)
    return new_csvfile


# global variables
df = None
topic_to_id = None
id_to_topic = None
features = None
labels = None


# creating and shuffling the csv file (corpus)
def prepare_corp():
    csv, dataclass_size = create_csv()
    shuffled_csv = shuffle_csv(csv)
    global df, topic_to_id, id_to_topic, features, labels
    df = pd.read_csv(shuffled_csv)
    df.head()
    col = ['document', 'topic']
    df = df[col]

    df['topic_id'] = df['topic'].factorize()[0]
    topic_id_df = df[['topic', 'topic_id']].drop_duplicates().sort_values('topic_id')
    pickle.dump(topic_id_df, open(TOPIC_ID_DF_PATH, "wb"))
    topic_to_id = dict(topic_id_df.values)
    id_to_topic = dict(topic_id_df[['topic_id', 'topic']].values)
    tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='utf-8', ngram_range=(1, 2))
    features = tfidf.fit_transform(df.document).toarray()
    labels = df.topic_id
    pickle.dump(tfidf, open(TFIDF_PATH, "wb"))

    return dataclass_size


def create(model, dataclass_size):
    X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df.index,
                                                                                     test_size=0.33, random_state=0,
                                                                                     stratify=labels)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    joblib.dump(model, MODEL_PATH)
    # print out the classification report for each class
    out_dict = metrics.classification_report(y_test, y_pred, target_names=df['topic'].unique(), output_dict=True)

    update_cl_report(data_per_class=dataclass_size, accuracy=out_dict.get('accuracy'), hadj=out_dict.get('Hadj'), salat=out_dict.get('Salat'),
                     sawm=out_dict.get('Sawm'),
                     zakat=out_dict.get('Zakat'))

    data_frame = pd.DataFrame(out_dict).transpose()
    file = StringIO()
    data_frame.to_csv(file)
    return file


def create_model():
    dataclass_size = prepare_corp()
    model = LinearSVC()
    return create(model=model, dataclass_size=dataclass_size)


def predict_class(query_document):
    tfidf = pickle.load(open(TFIDF_PATH, "rb"))
    transformed_query = tfidf.transform([query_document])
    loaded_model = joblib.load(MODEL_PATH)
    predict = loaded_model.predict(transformed_query)
    topic_id_df = pickle.load(open(TOPIC_ID_DF_PATH, "rb"))
    prediction = topic_id_df.values[predict]
    return prediction[0][0]
